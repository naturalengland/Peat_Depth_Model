---
title: "Peat Depth Model: Evaluate"
params:
  params_fn: 
    input: file
    label: 'Select parameters to import (.rds)'
    value: "../data/parameters_spade.rds"
  model_fn: 
    input: file
    label: 'Select model to import (.rds)'
    value: "../outputs/model.geo__spade_run_20200806-1552.rds"
  inputs_fn: 
    input: file
    label: 'Select input data to import (.rds)'
    value: "../outputs/input.data.gs_spade_run_20200806-1612.rds"
output:
    html_notebook:
    html_document:
    df_print: paged

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo= TRUE)
source("rsquared_funs.R")
```

-------  

Run at `r Sys.time()` for **`r params$area_name`** (*`r params$area_abbr`*) with the following parameters: 

```{r, echo=FALSE}
#import parameters from previous runs
parameters <- readRDS(file = params$params_fn)

# if you need to change any imported parameters, do it here, e.g.: 
  #parameters$existing_parameter <- newvalue
  #parameters$new_parameter <- value

# add new parameters from yaml header

parameters <- c(parameters, params)

# print list of all parameters
parameters
  
#store graphics params in case things go wrong
par.ori <- par() #save default plotting parameters


```


-------    

## Introduction

This script evaluates a model using ten-fold cross validation and produces evaluation metrics.  



```{r}
#load packages
library(tidyverse)#
library(raster)
library(rgdal)
library(sp)
library(sf)
library(elevatr)
library(geoR)
library(gstat)
library(stars)
```
## 1. Import previously prepared data


## 4. Ten-fold cross validation    

This analysis uses the `gstat` function `krige.cv()` to perform ten-fold cross validation

import model and data
```{r}
if(!exists("model.geo")){model.geo <- readRDS(parameters$model_fn)}
if(!exists("sp_depth")){sp_depth <- readRDS(parameters$inputs_fn)}
```

```{r}
set.seed(4321)
```



```{r}
sm.cv <- krige.cv(formula = cbrt_depth ~ elev + slope, 
                       locations = sp_depth, 
                       model = model.geo, 
                       nfold=10)
names(sm.cv) <- c("pred.sm", "var.sm", "obs.tf", "resid.sm", "zscore.sm", "fold.sm")

```

```{r}
bubble(sm.cv, "resid.sm", main = "10-fold CV residuals")
```
```{r}
intervals.sm <- sm.cv@data %>% mutate( 
  LPI.sm = pred.sm - 1.96 * sqrt(var.sm),
  UPI.sm = pred.sm + 1.96 * sqrt(var.sm),
  obsInInt.sm = obs.tf < UPI.sm & obs.tf > LPI.sm) %>% 
  select(pred.sm, var.sm, obs.tf, LPI.sm, UPI.sm, obsInInt.sm)
```

```{r}
sm.cv@data
```

```{r}
cat(sep = "", "Spatial model cross-validation metrics (not back-transformed):",
# mean error, ideally 0:
"\nmean error = ", mean(sm.cv$resid.sm) %>% round(3), 
# MSPE, ideally small
", MSPE = ", mean(sm.cv$resid.sm^2) %>% round(3),
#Mean square normalized error, ideally close to 1
", mean square norm. error = ", mean(sm.cv$zscore.sm^2) %>% round(3),
# correlation observed and predicted, ideally 1
", \ncor obs&pred = ", cor(sm.cv$obs.tf, sm.cv$pred.sm) %>% round(3),
# correlation predicted and residual, ideally 0
", cor pred&resid = ", cor(sm.cv$pred.sm, sm.cv$resid.sm) %>% round(3),
# RSquared
", R2 = ", rsq(observed = sm.cv$obs.tf, predicted = sm.cv$pred.sm) %>% round(3),
# Adjusted RSquared
", R2 adj = ", rsq.adj(observed = sm.cv$obs.tf, predicted = sm.cv$pred.sm, n.predictors = 3, df.int = 1) %>% round(3)
)
```

```{r}
#linear model cv
lm.cv <- krige.cv(formula = cbrt_depth ~ elev + slope, 
                       locations = sp_depth, 
                       model = NULL, 
                       nfold=10)
names(lm.cv) <- c("pred.lm", "var.lm", "obs.tf", "resid.lm", "zscore.lm", "fold.lm")

#bubble(lm.cv, "residual", main = "10-fold CV residuals")#
```


```{r}
cat(sep = "", "Linear model cross-validation metrics (not back-transformed):",
# mean error, ideally 0:
"\nmean error = ", mean(lm.cv$resid.lm) %>% round(3), 
# MSPE, ideally lmall
", MSPE = ", mean(lm.cv$resid.lm^2) %>% round(3),
#Mean square normalized error, ideally close to 1
", mean square norm. error = ", mean(lm.cv$zscore.lm^2) %>% round(3),
# correlation observed and predicted, ideally 1
", \ncor obs&pred = ", cor(lm.cv$obs.tf, lm.cv$pred.lm) %>% round(3),
# correlation predicted and residual, ideally 0
", cor pred&resid = ", cor(lm.cv$pred.lm, lm.cv$resid.lm) %>% round(3),
# RSquared
", R2 = ", rsq(observed = lm.cv$obs.tf, predicted = lm.cv$pred.lm) %>% round(3),
# Adjusted RSquared
", R2 adj = ", rsq.adj(observed = lm.cv$obs.tf, predicted = lm.cv$pred.lm, n.predictors = 3, df.int = 1) %>% round(3)
)
```




```{r}
#calc intervals and backtransform
intervals.lm <- lm.cv@data %>% mutate(
  LPI.lm = pred.lm - 1.96 * sqrt(var.lm),
  UPI.lm = pred.lm + 1.96 * sqrt(var.lm),
  obsInInt.lm = obs.tf < UPI.lm & obs.tf > LPI.lm) %>% 
  select(pred.lm, var.lm, obs.tf, LPI.lm, UPI.lm, obsInInt.lm)
intervals.lm %>% data.frame() %>% colMeans()
```


```{r}
#merge cv datasets and backtransform
results.cv <- cbind(sm = sm.cv, lm = lm.cv)
results.cv <- results.cv@data %>% mutate(
  obs.btf = obs.tf^3, 
  pred.sm.btf = pred.sm^3, 
  pred.lm.btf = results.cv$pred.lm^3) %>% 
  select(-obs.tf.1)
```


```{r}
# summarise backtransformed cross-validation results
cv <- results.cv %>% summarise(
  rmse.lm = rmse(observed = obs.btf, predicted = pred.lm.btf) %>% round(3), 
  r2.lm = rsq(observed = obs.btf, predicted = pred.lm.btf) %>% round(3),
  r2adj.lm = rsq.adj(observed = obs.btf, predicted = pred.lm.btf, n.predictors = 3, df.int = 1) %>% round(3),
  coverage.lm = mean(intervals.lm$obsInInt.lm), 
  bias.lm = mean(pred.lm.btf - obs.btf), 
  interv.lm = mean(intervals.lm$UPI.lm - intervals.lm$LPI.lm)^3, 
  rmse.sm = rmse(observed = obs.btf, predicted = pred.sm.btf) %>% round(3), 
  r2.sm = rsq(observed = obs.btf, predicted = pred.sm.btf) %>% round(3),
  r2adj.sm =  rsq.adj(observed = obs.btf, predicted = pred.sm.btf, n.predictors = 3, df.int = 1) %>% round(3),
  coverage.sm = mean(intervals.sm$obsInInt.sm), 
  bias.sm = mean(pred.sm.btf - obs.btf), 
  interv.sm = mean(intervals.sm$UPI.sm - intervals.sm$LPI.sm)^3
)
t(cv)
```


```{r}
# summarise data and covariate space
predictors <- raster::stack(parameters$elev_raster_fn, parameters$slope_raster_fn)
names(predictors) <- c("elevation", "slope")

prdr.summ <- data.frame(dataset = "predictors", n_points = ncell(predictors), depth_med = as.numeric(NA), 
            depth_min = as.numeric(NA), depth_max = as.numeric(NA),
            elev_min = minValue(predictors$elevation) %>% round(2), elev_max = maxValue(predictors$elevation) %>% round(2),
            slope_min = minValue(predictors$slope) %>% round(2), slope_max = maxValue(predictors$slope) %>% round(2))
obs.summ <- sp_depth@data %>% summarise(dataset = "observations extract", n_points = length(depth), depth_med = median(depth), 
                  depth_min = min(depth), depth_max = max(depth), elev_min = min(elev), elev_max = max(elev),
                  slope_min = min(slope), slope_max = max(slope))
rbind(prdr.summ, obs.summ)
```


## Calculate null model and literature model


```{r}
#null model lm
lm.depth <- lm(depth ~ elev + slope, sp_depth)
summary(lm.depth)

pred.lm <- lm.depth$fitted.values
obs.lm <- lm.depth$model$depth

paste0("R2 = ", rsq(observed = obs.lm, predicted = pred.lm) %>% round(3),
      ", R2 adj = ", rsq.adj(observed = obs.lm, predicted = pred.lm,
                             n.predictors = 2, df.int = 1) %>% round(3),
      ", RMSE = ", rmse(observed = obs.lm, predicted = pred.lm) %>% round(3), " cm")

model_equation(model = lm.depth)
```


```{r}
# Parry 1
#  lpdepth=Exp(0.875+0.00758*"dtm_metres"-0.0903*"slope_england")-25+(0.5*Exp(0.875+0.00758*"dtm_metres"-0.0903*"slope_england"))

pred.parry <- exp(0.875 + 0.00758 * sp_depth$elev - 0.0903 * sp_depth$slope) - 25 + (0.5 * exp(0.875 + 0.00758 * sp_depth$elev - 0.0903 * sp_depth$slope))


paste0("R2 = ", rsq(observed = sp_depth$depth, predicted = pred.parry) %>% round(3),
      ", R2 adj = ", rsq.adj(observed = sp_depth$depth, predicted = pred.parry,
                             n.predictors = 2, df.int = 1) %>% round(3),
      ", RMSE = ", rmse(observed = sp_depth$depth, predicted = pred.parry) %>% round(3), " cm")

```

#>>>> got this
#### Write everything to big dataframe
need to also bind backtransformed results into this
```{r}
#combine original data and predictions
results.df <- cbind(id = seq(1:nrow(sp_depth)), 
                    sp_depth@data, 
                    results.cv, 
                    intervals.lm[c("LPI.lm", "UPI.lm", "obsInInt.lm")], 
                    intervals.sm[c("LPI.sm", "UPI.sm", "obsInInt.sm")],
                    pred.null = lm.depth$fitted.values,
                    pred.parry
                    )
results.df
#'##I need to do the above again.  Need to chunk this into model types.  

#make tidy data
results.ty <- gather(results.df, key = key, value = value, pred_LM.1:UPI_SM.10) %>% 
  separate(col = key, into = c("key", "modeltype", "run")) %>% 
  spread(key = key, value = value)
results.ty

```

```{r}
str(results)
class(results)
results[101,,]
results[101,2,]
```


------------------------------------------------------------------------------

## 5. Summarise the results  

### Compute metrics of interest  

```{r}
#### Bias  
# - measures whether the predictions are too large or too small on average
# - want to be as close to zero as possible but due to random variation will not be exactly zero.
# - mean of prediction minus observation

# Linear model
bias.lm <- mean(results.btf[,1, ] - matrix(rep(dat$depth,10), nrow=n, ncol=10,
                            byrow=FALSE))
# Spatial model
bias.sm <- mean(results.btf[,4, ] - matrix(rep(dat$depth,10), nrow=n, ncol=10,
                          byrow=FALSE), na.rm = T) #bodge to deal with NAs

#### RMSE  
# - measures average difference between the true and predicted values ignoring sign. 
# - want to be as small as possible  

# Linear model
rmse.lm <- sqrt(mean((results.btf[,1, ] - matrix(rep(dat$depth,10), nrow=n, ncol=10,
                                  byrow=FALSE))^2)) 

###getting NAs here
# Spatial model
rmse.sm <- sqrt(mean((results.btf[,4, ] - matrix(rep(dat$depth,10), nrow=n, ncol=10,
                                  byrow=FALSE))^2, na.rm = T))  #bodge to deal with NaNs


#### Coverage 
# - measures the probability that the 95% prediction intervals contain the true value 
# - want to be 0.95

# Linear model
coverage.lm <- mean(matrix(rep(dat$depth,10), nrow=n, ncol=10, byrow=FALSE) >
     results.btf[ ,2, ] & matrix(rep(dat$depth,10), nrow=n, ncol=10,
                             byrow=FALSE) < results.btf[ ,3, ])
# Spatial model
coverage.sm <- mean(matrix(rep(dat$depth,10), nrow=n, ncol=10, byrow=FALSE) >
     results.btf[ ,5, ] & matrix(rep(dat$depth,10), nrow=n, ncol=10,
                             byrow=FALSE) < results.btf[ ,6, ], na.rm = T) #bodge to deal with NAs

#### Interval width   
# - the width of the 95% prediction intervals
# - want to be as small as possible provided that the coverage above is around 0.95. If the coverage is much lower than 0.95 then this is meaningless.

# Linear model
interv.lm <- mean(results.btf[ ,3, ] - results.btf[ ,2, ])
# Spatial model
interv.sm <- mean(results.btf[ ,6, ] - results.btf[ ,5, ], na.rm = T) #bodge to deal with NAs


table.metrics <- data.frame(rbind(
  LM = c(bias = bias.lm, RMSE = rmse.lm, coverage = coverage.lm, interval_width = interv.lm), 
  SM = c(bias = bias.sm, RMSE = rmse.sm, coverage = coverage.sm, inverval_width = interv.sm)))

table.metrics
```

### visualise predictions

```{r}
graphdata <- results.ty %>% #filter(modeltype == "LM") %>% 
  mutate(pred_backtr = pred^2) %>% 
  group_by(modeltype, id) %>% 
  summarise(sqrt_depth = mean(sqrt_depth),
            sqrt_pred = mean(pred),
            depth = mean(depth),
            pred_backtr = mean(pred_backtr)) #calculate mean result for each point

graphmetrics <- graphdata %>% 
  group_by(modeltype) %>% 
  summarise(RMSE =      sqrt(mean((depth -      pred_backtr)^2)),
            RMSE_sqrt = sqrt(mean((sqrt_depth - sqrt_pred)^2)),
            cc = cor(depth, (pred_backtr)))



ggplot(graphdata, aes(x = depth, y = pred_backtr)) +
  geom_point(aes(colour = modeltype, shape = modeltype), position = position_dodge(width = 2))+
  geom_abline(slope = 1) +
  coord_equal() +
  geom_text(data = graphmetrics, 
            aes(x = 50, y = c(140,160), colour = modeltype,
                label = paste("RMSE =", round(RMSE, 2),
                              "cm (backtransf.) \nCC =", round(cc, 2))),
            size = 3, show.legend = F) +
  labs(title = paste("Predicted v observed values \n", rundate))

  
ggsave(filename = paste0("../outputs/predvobs__", 
                         parameters$area_abbr, "_",
                         rundate, ".png"))
```


```{r}
class(model.geo)
summary(model.geo)

```

------------------------------------------------------------------------------  
## 5.5 Summary outputs

### Table 1. Summary statistics for input and prediction data

```{r}
rbind(
dat %>% summarise(dataset = "observations extract",
                  n_points = length(depth), depth_med = median(depth), 
                  depth_min = min(depth), depth_max = max(depth),
                  elev_min = min(elev), elev_max = max(elev),
                  slope_min = min(slope), slope_max = max(slope))
,

c(dataset = "predictors", n_points = ncell(predictors), depth_med = as.numeric(NA), 
            depth_min = as.numeric(NA), depth_max = as.numeric(NA),
            elev_min = minValue(predictors$elevation), elev_max = maxValue(predictors$elevation),
            slope_min = minValue(predictors$slope), slope_max = maxValue(predictors$slope))
)

```



### Table 2. Performance metrics for spatial and linear models from 10-fold cross-validation simulations


```{r}
table.metrics
```

### Table xx. combined metrics for each model run

```{r}
#compile metrics
metrics.combined <- data.frame(
  run = rundate,
  dat = dat %>% summarise(n_points = length(depth), depth_med = median(depth), 
                          depth_min = min(depth), depth_max = max(depth),
                          elev_min = min(elev), elev_max = max(elev),
                          slope_min = min(slope), slope_max = max(slope)), 
  cv = data.frame(bias.lm, rmse.lm, coverage.lm, interv.lm, bias.sm, rmse.sm, coverage.sm, interv.sm),
  prdr = data.frame(dataset = "predictors", n_points = ncell(predictors), depth_med = as.numeric(NA), 
            depth_min = as.numeric(NA), depth_max = as.numeric(NA),
            elev_min = minValue(predictors$elevation), elev_max = maxValue(predictors$elevation),
            slope_min = minValue(predictors$slope), slope_max = maxValue(predictors$slope)),
  mod = data.frame(model.geo[c(1, 2, 4, 5, 6)],
                   intercept = model.geo$beta[[1]],
                   covar1 = model.geo$beta[[2]],
                   covar2 = model.geo$beta[[3]], 
                   model.geo[c(11, 12, 15, 17, 18)])
)


#make tidy
metrics.combined <- metrics.combined %>% mutate_all(as.character) %>% gather(key = metric, value = value, -run); metrics.combined 
#add to csv record
ifelse(file.exists("../outputs/metrics_combined.csv"), 
       yes = write_csv(metrics.combined, "../outputs/metrics_combined.csv", col_names = F, append = T), 
       no = write_csv(metrics.combined, "../outputs/metrics_combined.csv", col_names = T, append = F))
```




------------------------------------------------------------------------------  

## 6. Do some plots

##Variograms

#### Plot the semi-variogram to test for the presence of spatial autocorrelation

```{r}
residuals <- residuals(mod.lm.test)
resid.sp <- as.geodata(obj=dat.fit, coords.col=c("x", "y"), data.col="sqrt_depth", covar.col = c("elev", "slope"))
resid.sp <- jitterDupCoords(resid.sp, max=0.01)
vari1 <- variog(resid.sp)
vari1.mc <- variog.mc.env(resid.sp, obj.variog=vari1)

plot(vari1, envelope.obj = vari1.mc, xlab="Distance (m)",
     ylab="Estimated semi-variogram", main = "Spatial autocorrelation of residuals")
```

#### Empirical variograms
Empirical variograms are calculated using the function variog. There are options for the classical or modulus estimator. Results can be returned as variogram clouds, binned or smoothed variograms.

```{r}
plot(variog(input.data.gd))
```



```{r}
max_dist <- 400
cloud1 <- variog(input.data.gd, option = "cloud")#, max.dist = max_dist)
cloud2 <- variog(input.data.gd, option = "cloud", estimator.type = "modulus")#, max.dist = max_dist)
bin1 <- variog(input.data.gd)#, uvec=seq(0, max_dist, l=11))
bin2  <- variog(input.data.gd, estimator.type= "modulus")#, uvec=seq(0, max_dist, l=11))

par(mfrow=c(2,2), pch = 1)
plot(cloud1, main = "cloud: classical estimator")
plot(cloud2, main = "cloud: modulus estimator")
plot(bin1, main = "binned: classical estimator")
plot(bin2, main = "binned: modulus estimator")
#par(par.ori)
```
	  


##Compare model outputs

```{r}
#read in metrics from csv
model_metrics <- read_csv("../outputs/metrics_combined.csv")
```


```{r}
model_metrics_w <- model_metrics %>% spread(key = metric, value = value)
model_metrics_w
```

```{r}
ggplot(model_metrics_w, aes(x = cv.rmse.sm, y = cv.rmse.lm)) +
  geom_point(aes(colour = run)) +
  coord_equal() +
  expand_limits(x = 0, y = 0)


ggplot(model_metrics_w, aes(x = dat.n_points, y = cv.rmse.sm)) +
  geom_point(aes(colour = run))

```


```{r}
# export parameters
saveRDS(parameters,  paste0("../data/parameters_", 
                                      parameters$area_abbr, ".rds"))
```
